# ğŸ“¦ **Single-View 3D Object Reconstruction Using Deep Neural Networks**

Reconstructing a complete **3D voxel model** from a single 2D RGB image is one of the core challenges in computer vision.
This project implements a **deep neural network (CNN + 3D decoder)** that learns to map a single image into a 3D voxel grid, enabling the estimation of 3D object geometry from limited visual information.

This repository includes the full pipeline:

âœ” Preprocessing and dataset conversion
âœ” Neural network architecture
âœ” Model training
âœ” 3D voxel + mesh generation
âœ” Visualization & inference scripts

---

## ğŸš€ **Project Demo**

| Input Image | 3D Reconstruction     |
| ----------- | --------------------- |
| 2D Image â†’  | Voxel / Mesh Output â†’ |

*(Add your own sample outputs here after running inference.)*

---

## ğŸ§  **Model Architecture**

The model follows a **CNN Encoder â†’ Fully Connected Bottleneck â†’ 3D Decoder** design.

**Encoder (2D CNN):**

* Learns visual features from single-view RGB input
* Uses stacked convolution + batch norm + ReLU
* Outputs a compact latent embedding

**Latent Vector:**

* Dense representation capturing object structure

**Decoder (3D CNN):**

* Transposes convolutions to upsample
* Outputs a **32Ã—32Ã—32 voxel grid**
* Final activation: Sigmoid (for occupancy probability)

> ğŸ“Œ Architecture diagram is included in repo:
> **`architecture_diagram.png`**

---

## ğŸ“‚ **Repository Structure**

```
.
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ pix3d_to_voxel_dataset.py        # Convert Pix3D to images + voxel grids
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py                        # Dataset loader
â”‚   â”œâ”€â”€ preprocess.py                     # Image preprocessing
â”‚   â”œâ”€â”€ model.py                          # Encoder-decoder neural network
â”‚   â”œâ”€â”€ train.py                          # Training pipeline
â”‚   â”œâ”€â”€ utils.py                          # IoU, voxel slicing, mesh export
â”‚   â””â”€â”€ predict.py                        # Inference script
â”‚
â”œâ”€â”€ main.py                               # Train launcher
â”œâ”€â”€ view_3d_model.py                      # Display .ply meshes (Trimesh)
â”œâ”€â”€ requirements.txt                      # Dependencies
â”œâ”€â”€ architecture_diagram.png              # Model architecture
â”œâ”€â”€ 3D_Reconstruction_Project_Documentation_Upgraded.docx
â””â”€â”€ README.md
```

---

## ğŸ“¦ **Installation**

### 1ï¸âƒ£ Clone repository

```
git clone https://github.com/<your-username>/Single-View-3D-Object-Reconstruction-Using-Deep-Neural-Networks.git
cd Single-View-3D-Object-Reconstruction-Using-Deep-Neural-Networks
```

### 2ï¸âƒ£ Create virtual environment (optional)

```
python -m venv venv
venv\Scripts\activate   # Windows
```

### 3ï¸âƒ£ Install dependencies

```
pip install -r requirements.txt
```

---

## ğŸ“ **Dataset**

This project expects images + voxel grids.

You may use:

### **Pix3D Dataset**

* Not included in this repository (too large)
* Download from: [https://github.com/xingyuankuang/pix3d](https://github.com/xingyuankuang/pix3d)

Then convert to voxel format using:

```
python scripts/pix3d_to_voxel_dataset.py
```

This will produce:

```
dataset/
 â”œâ”€â”€ images/
 â””â”€â”€ voxels/
```

---

## ğŸ‹ï¸ **Training the Model**

Run:

```
python main.py
```

Training includes:

* BCE loss on voxel occupancy
* IoU metric
* Model checkpoints
* Visualization of voxel slices per epoch

Results saved under:

```
results/saved_models/
results/visualizations/
```

---

## ğŸ” **Inference (Reconstruction)**

To generate a 3D model from a single 2D image:

```
python -m src.predict --image path/to/image.jpg --model results/saved_models/reconstructor_epochXX.pth
```

Outputs:

* `pred_slices.png` â†’ voxel slices
* `pred_mesh.ply` â†’ 3D mesh (viewable in MeshLab / Blender)

Use this to visualize:

```
python view_3d_model.py
```

---

## ğŸ“ˆ **Evaluation**

Metrics:

* **IoU (Intersection-over-Union)** for voxel prediction
* Loss curves visualized per epoch
* Optionally export meshes for qualitative analysis

---

## ğŸ§¾ **.gitignore (Important)**

Large items **NOT uploaded** to repo:

* `dataset/`
* `pix3d/`
* `results/`
* `venv/`
* `*.ply`

(Already included in your repo.)

---

## ğŸ“š **References**

1. **Pix3D Dataset** â€” Sun et al. *"Pix3D: Dataset and Methods for Single-View 3D Reconstruction"*, CVPR 2018
2. **3D CNNs** â€” Wu et al., *"Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling"*
3. PyTorch Documentation â€” [https://pytorch.org](https://pytorch.org)
4. Trimesh Library â€” [https://trimsh.org](https://trimsh.org)
5. Kingma & Ba â€” *Adam Optimizer*



